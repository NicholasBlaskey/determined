CREATE TYPE checkpoint_storage_type AS ENUM (
  'shared_fs',
  's3',
  'gcs',
  'azure',
  'directory'
);

CREATE TABLE storage_backend (
  id integer PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
  type checkpoint_storage_type NOT NULL,

  shared_fs_host_path        TEXT,
  shared_fs_container_path   TEXT,
  shared_fs_checkpoint_path  TEXT,
  shared_fs_tensorboard_path TEXT,
  shared_fs_storage_path     TEXT,
  shared_fs_propagation      TEXT,
  CONSTRAINT shared_fs_required_fields CHECK (type != 'shared_fs' OR (
    shared_fs_host_path IS NOT NULL AND
    shared_fs_propagation IS NOT NULL
  )),
  CONSTRAINT shard_fs_type_set CHECK (type = 'shared_fs' OR NOT (
    shared_fs_host_path IS NOT NULL OR
    shared_fs_container_path IS NOT NULL OR
    shared_fs_checkpoint_path IS NOT NULL OR
    shared_fs_tensorboard_path IS NOT NULL OR
    shared_fs_storage_path IS NOT NULL OR
    shared_fs_propagation IS NOT NULL
  )),

  s3_bucket       TEXT,
  s3_access_key   TEXT,
  s3_secret_key   TEXT,
  s3_endpoint_url TEXT,
  s3_prefix       TEXT,
  CONSTRAINT s3_required_fields CHECK (type != 's3' OR (
    s3_bucket IS NOT NULL
  )),

  gcs_bucket TEXT,
  gcs_prefix TEXT,
  CONSTRAINT gcs_required_fields CHECK (type != 'gcs' OR (
    gcs_bucket IS NOT NULL
  )),

  azure_container         TEXT,
  azure_connection_string TEXT,
  azure_account_url       TEXT,
  azure_credential        TEXT,
  CONSTRAINT azure_required_fields CHECK (type != 'azure' OR (
    NOT (azure_container IS NULL) AND
    NOT (azure_connection_string IS NOT NULL AND azure_account_url IS NOT NULL) AND
    NOT (azure_connection_string IS NOT NULL AND azure_credential IS NOT NULL)
  )),

  directory_container_path TEXT,
  CONSTRAINT directory_required_fields CHECK (type != 'directory' OR (
    directory_container_path IS NOT NULL
  ))
);

-- Hack for lack of pre-postgres 15 NULLS NOT DISTINCT.
-- https://stackoverflow.com/questions/8289100/create-unique-constraint-with-null-columns
CREATE UNIQUE INDEX ix_storage_backend_unique_fs ON storage_backend (
  COALESCE(shared_fs_host_path, 'DeterminedReservedNullUniqueValue'),
  COALESCE(shared_fs_container_path, 'DeterminedReservedNullUniqueValue'),
  COALESCE(shared_fs_checkpoint_path, 'DeterminedReservedNullUniqueValue'),
  COALESCE(shared_fs_tensorboard_path, 'DeterminedReservedNullUniqueValue'),
  COALESCE(shared_fs_storage_path, 'DeterminedReservedNullUniqueValue'),
  COALESCE(shared_fs_propagation, 'DeterminedReservedNullUniqueValue')
) WHERE type = 'shared_fs';

CREATE UNIQUE INDEX ix_storage_backend_unique_s3 ON storage_backend (
  COALESCE(s3_bucket, 'DeterminedReservedNullUniqueValue'),
  COALESCE(s3_access_key, 'DeterminedReservedNullUniqueValue'),
  COALESCE(s3_secret_key, 'DeterminedReservedNullUniqueValue'),
  COALESCE(s3_endpoint_url, 'DeterminedReservedNullUniqueValue'),
  COALESCE(s3_prefix, 'DeterminedReservedNullUniqueValue')
) WHERE type = 's3';

CREATE UNIQUE INDEX ix_storage_backend_unique_gcs ON storage_backend (
  COALESCE(gcs_bucket, 'DeterminedReservedNullUniqueValue'),
  COALESCE(gcs_prefix, 'DeterminedReservedNullUniqueValue')
) WHERE type = 'gcs';

CREATE UNIQUE INDEX ix_storage_backend_unique_azure ON storage_backend (
  COALESCE(azure_container, 'DeterminedReservedNullUniqueValue'),
  COALESCE(azure_connection_string, 'DeterminedReservedNullUniqueValue'),
  COALESCE(azure_account_url, 'DeterminedReservedNullUniqueValue'),
  COALESCE(azure_credential, 'DeterminedReservedNullUniqueValue')
) WHERE type = 'azure';

CREATE UNIQUE INDEX ix_storage_backend_unique_directory ON storage_backend (
  COALESCE(directory_container_path, 'DeterminedReservedNullUniqueValue')
) WHERE type = 'directory';

ALTER TABLE checkpoints_v2
  ADD COLUMN storage_id int REFERENCES storage_backend(id);

DROP VIEW proto_checkpoints_view;
DROP VIEW checkpoints_view;

CREATE OR REPLACE VIEW checkpoints_view AS
    SELECT
        c.id AS id,
        c.uuid AS uuid,
        c.task_id,
        c.allocation_id,
        c.report_time,
        c.state,
        c.resources,
        c.metadata,
        t.id AS trial_id,
        e.id AS experiment_id,
        e.config AS experiment_config,
        t.hparams AS hparams,
        s.metrics AS training_metrics,
        v.metrics->'validation_metrics' AS validation_metrics,
        (v.metrics->'validation_metrics'->>(e.config->'searcher'->>'metric'))::float8 AS searcher_metric,
        CAST(c.metadata->>'steps_completed' AS int) as steps_completed,
        c.size,
        c.storage_id
    FROM checkpoints_v2 AS c
    LEFT JOIN trial_id_task_id AS task ON c.task_id = task.task_id
    LEFT JOIN trials AS t on t.id = task.trial_id
    LEFT JOIN experiments AS e on t.experiment_id = e.id
    LEFT JOIN raw_validations AS v on CAST(c.metadata->>'steps_completed' AS int) = v.total_batches and t.id = v.trial_id AND NOT v.archived
    LEFT JOIN raw_steps AS s on CAST(c.metadata->>'steps_completed' AS int) = s.total_batches and t.id = s.trial_id AND NOT s.archived;

CREATE OR REPLACE VIEW proto_checkpoints_view AS
    SELECT
        c.uuid::text AS uuid,
        c.task_id,
        c.allocation_id,
        c.report_time as report_time,
        'STATE_' || c.state AS state,
        c.resources,
        c.metadata,
        c.storage_id,
        -- Build a training substruct for protobuf.
        jsonb_build_object(
            'trial_id', c.trial_id,
            'experiment_id', c.experiment_id,
            'experiment_config', c.experiment_config,
            'hparams', c.hparams,
            -- construct training metrics from the untyped jsonb deterministically, since older
            -- versions may have old keys (e.g., num_inputs) and our unmarshaling is strict.
            'training_metrics', jsonb_build_object(
                'avg_metrics', c.training_metrics->'avg_metrics',
                'batch_metrics', c.training_metrics->'batch_metrics'
            ),
            'validation_metrics', json_build_object('avg_metrics', c.validation_metrics),
            'searcher_metric', c.searcher_metric
        ) AS training
    FROM checkpoints_view AS c;;
